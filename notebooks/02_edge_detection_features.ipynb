{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81060f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ace30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "image_path = \"../data/raw/my_dogs.jpg\"\n",
    "\n",
    "if not Path(image_path).exists():\n",
    "    print(\"âš ï¸  Using sample image\")\n",
    "    image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)\n",
    "else:\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "print(f\"Image loaded: {image.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb3254b",
   "metadata": {},
   "source": [
    "## 2.1 Gradient-Based Edge Detection\n",
    "\n",
    "Edges occur where pixel intensity changes rapidly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fbdfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sobel edge detection (gradients in X and Y)\n",
    "sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "sobel_combined = np.sqrt(sobelx**2 + sobely**2)\n",
    "sobel_combined = np.uint8(sobel_combined / sobel_combined.max() * 255)\n",
    "\n",
    "# Laplacian (second derivative)\n",
    "laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "laplacian = np.uint8(np.absolute(laplacian))\n",
    "\n",
    "# Canny edge detection\n",
    "canny = cv2.Canny(gray, 50, 150)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "axes[0, 0].imshow(gray, cmap='gray')\n",
    "axes[0, 0].set_title('Original Grayscale', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(sobelx, cmap='gray')\n",
    "axes[0, 1].set_title('Sobel X (Vertical edges)', fontsize=12)\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[0, 2].imshow(sobely, cmap='gray')\n",
    "axes[0, 2].set_title('Sobel Y (Horizontal edges)', fontsize=12)\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "axes[1, 0].imshow(sobel_combined, cmap='gray')\n",
    "axes[1, 0].set_title('Sobel Combined', fontsize=12)\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(laplacian, cmap='gray')\n",
    "axes[1, 1].set_title('Laplacian (2nd derivative)', fontsize=12)\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "axes[1, 2].imshow(canny, cmap='gray')\n",
    "axes[1, 2].set_title('Canny Edge Detection', fontsize=12)\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.suptitle('Edge Detection Methods', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cf6470",
   "metadata": {},
   "source": [
    "## 2.2 Canny Edge Detection - Multi-Stage\n",
    "\n",
    "Canny is the most popular edge detector (5 stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba9ca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different threshold values for Canny\n",
    "canny_low = cv2.Canny(gray, 30, 100)\n",
    "canny_mid = cv2.Canny(gray, 50, 150)\n",
    "canny_high = cv2.Canny(gray, 100, 200)\n",
    "\n",
    "# Overlay edges on original image\n",
    "overlay = image_rgb.copy()\n",
    "overlay[canny_mid > 0] = [255, 0, 0]  # Red edges\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "axes[0, 0].imshow(canny_low, cmap='gray')\n",
    "axes[0, 0].set_title('Canny (30, 100) - More edges', fontsize=11)\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(canny_mid, cmap='gray')\n",
    "axes[0, 1].set_title('Canny (50, 150) - Balanced', fontsize=11)\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[1, 0].imshow(canny_high, cmap='gray')\n",
    "axes[1, 0].set_title('Canny (100, 200) - Strong edges only', fontsize=11)\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(overlay)\n",
    "axes[1, 1].set_title('Edges Overlay on Original', fontsize=11)\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ðŸ“š Canny Algorithm Steps:\")\n",
    "print(\"  1. Gaussian blur (noise reduction)\")\n",
    "print(\"  2. Gradient calculation (Sobel)\")\n",
    "print(\"  3. Non-maximum suppression (thin edges)\")\n",
    "print(\"  4. Double threshold (strong/weak edges)\")\n",
    "print(\"  5. Edge tracking by hysteresis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d0a28e",
   "metadata": {},
   "source": [
    "## 2.3 Corner Detection\n",
    "\n",
    "Corners are important features for object tracking and matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a35917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harris Corner Detection\n",
    "gray_float = np.float32(gray)\n",
    "harris = cv2.cornerHarris(gray_float, blockSize=2, ksize=3, k=0.04)\n",
    "harris = cv2.dilate(harris, None)  # Dilate for visualization\n",
    "\n",
    "# Shi-Tomasi Corner Detection (Good Features to Track)\n",
    "corners = cv2.goodFeaturesToTrack(gray, maxCorners=100, qualityLevel=0.01, minDistance=10)\n",
    "\n",
    "# Visualize\n",
    "harris_img = image_rgb.copy()\n",
    "harris_img[harris > 0.01 * harris.max()] = [255, 0, 0]  # Red corners\n",
    "\n",
    "shi_tomasi_img = image_rgb.copy()\n",
    "if corners is not None:\n",
    "    for corner in corners:\n",
    "        x, y = corner.ravel()\n",
    "        cv2.circle(shi_tomasi_img, (int(x), int(y)), 3, (0, 255, 0), -1)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].imshow(image_rgb)\n",
    "axes[0].set_title('Original Image', fontsize=12, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(harris_img)\n",
    "axes[1].set_title(f'Harris Corners (red)', fontsize=12)\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(shi_tomasi_img)\n",
    "axes[2].set_title(f'Shi-Tomasi Corners (green) - {len(corners)} found', fontsize=12)\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20350d7",
   "metadata": {},
   "source": [
    "## 2.4 SIFT - Scale-Invariant Feature Transform\n",
    "\n",
    "SIFT detects keypoints that are invariant to scale and rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed86d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SIFT detector\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# Detect keypoints and compute descriptors\n",
    "keypoints_sift, descriptors_sift = sift.detectAndCompute(gray, None)\n",
    "\n",
    "# Draw keypoints\n",
    "img_sift = cv2.drawKeypoints(\n",
    "    image_rgb, keypoints_sift, None,\n",
    "    flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.imshow(img_sift)\n",
    "plt.title(f'SIFT Keypoints: {len(keypoints_sift)} detected', fontsize=14, fontweight='bold')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ“ SIFT found {len(keypoints_sift)} keypoints\")\n",
    "print(f\"âœ“ Descriptor shape: {descriptors_sift.shape if descriptors_sift is not None else 'None'}\")\n",
    "print(f\"\\nðŸ“ Each keypoint has:\")\n",
    "print(f\"  - Location (x, y)\")\n",
    "print(f\"  - Scale (size)\")\n",
    "print(f\"  - Orientation (angle)\")\n",
    "print(f\"  - 128-dimensional descriptor vector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9925acd2",
   "metadata": {},
   "source": [
    "## 2.5 ORB - Oriented FAST and Rotated BRIEF\n",
    "\n",
    "ORB is a fast, free alternative to SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55062f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ORB detector\n",
    "orb = cv2.ORB_create(nfeatures=500)\n",
    "\n",
    "# Detect keypoints and compute descriptors\n",
    "keypoints_orb, descriptors_orb = orb.detectAndCompute(gray, None)\n",
    "\n",
    "# Draw keypoints\n",
    "img_orb = cv2.drawKeypoints(\n",
    "    image_rgb, keypoints_orb, None,\n",
    "    color=(0, 255, 0),\n",
    "    flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.imshow(img_orb)\n",
    "plt.title(f'ORB Keypoints: {len(keypoints_orb)} detected', fontsize=14, fontweight='bold')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ“ ORB found {len(keypoints_orb)} keypoints\")\n",
    "print(f\"âœ“ Descriptor shape: {descriptors_orb.shape if descriptors_orb is not None else 'None'}\")\n",
    "print(f\"\\nâš¡ ORB Advantages:\")\n",
    "print(f\"  - Much faster than SIFT\")\n",
    "print(f\"  - Patent-free\")\n",
    "print(f\"  - Binary descriptors (smaller memory)\")\n",
    "print(f\"  - Good for real-time applications\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fe420d",
   "metadata": {},
   "source": [
    "## 2.6 Feature Comparison\n",
    "\n",
    "Compare all feature detection methods side-by-side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51272b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# Original\n",
    "axes[0, 0].imshow(image_rgb)\n",
    "axes[0, 0].set_title('Original Image', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "# Edges\n",
    "axes[0, 1].imshow(canny, cmap='gray')\n",
    "axes[0, 1].set_title(f'Canny Edges', fontsize=12)\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "# SIFT\n",
    "axes[1, 0].imshow(img_sift)\n",
    "axes[1, 0].set_title(f'SIFT: {len(keypoints_sift)} keypoints', fontsize=12)\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "# ORB\n",
    "axes[1, 1].imshow(img_orb)\n",
    "axes[1, 1].set_title(f'ORB: {len(keypoints_orb)} keypoints', fontsize=12)\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "plt.suptitle('Feature Detection Methods Comparison', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402af865",
   "metadata": {},
   "source": [
    "## 2.7 Contour Detection\n",
    "\n",
    "Find object boundaries in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3a2931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find contours\n",
    "contours, hierarchy = cv2.findContours(canny, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Filter by area\n",
    "min_area = 500\n",
    "large_contours = [c for c in contours if cv2.contourArea(c) > min_area]\n",
    "\n",
    "# Draw contours\n",
    "contour_img = image_rgb.copy()\n",
    "cv2.drawContours(contour_img, large_contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "# Draw bounding boxes\n",
    "bbox_img = image_rgb.copy()\n",
    "for contour in large_contours:\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    cv2.rectangle(bbox_img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "axes[0].imshow(contour_img)\n",
    "axes[0].set_title(f'Contours: {len(large_contours)} objects (area > {min_area})', fontsize=12)\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(bbox_img)\n",
    "axes[1].set_title('Bounding Boxes', fontsize=12)\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total contours found: {len(contours)}\")\n",
    "print(f\"Large contours (area > {min_area}): {len(large_contours)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62be73b",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**What we learned:**\n",
    "- âœ… Edge detection: Sobel, Laplacian, Canny\n",
    "- âœ… Corner detection: Harris, Shi-Tomasi\n",
    "- âœ… Keypoint detection: SIFT, ORB\n",
    "- âœ… Contour detection and bounding boxes\n",
    "- âœ… Feature descriptors for matching\n",
    "\n",
    "**Next:** Object Detection with YOLO â†’"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
