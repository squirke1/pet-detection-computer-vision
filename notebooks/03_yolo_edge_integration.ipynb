{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51aeec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from utils import (\n",
    "    load_image,\n",
    "    extract_edge_features,\n",
    "    detect_keypoints_sift,\n",
    "    detect_keypoints_orb,\n",
    "    detect_contours,\n",
    "    draw_detections,\n",
    "    draw_enhanced_detections\n",
    ")\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84938eaa",
   "metadata": {},
   "source": [
    "## 3.1 Load Image and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5122c783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test image\n",
    "image_path = \"../data/raw/my_dogs.jpg\"\n",
    "\n",
    "if not Path(image_path).exists():\n",
    "    print(\"‚ö†Ô∏è  Using sample image\")\n",
    "    image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)\n",
    "else:\n",
    "    image = load_image(image_path)\n",
    "\n",
    "# Load YOLO model\n",
    "model_path = \"../models/yolov8n-pets.pt\"\n",
    "if Path(model_path).exists():\n",
    "    model = YOLO(model_path)\n",
    "    print(f\"‚úÖ Model loaded from {model_path}\")\n",
    "else:\n",
    "    print(f\"‚ùå Model not found at {model_path}\")\n",
    "    print(\"   Please download or train a YOLOv8 model first\")\n",
    "\n",
    "print(f\"Image shape: {image.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72e0e79",
   "metadata": {},
   "source": [
    "## 3.2 Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3830038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract edge features\n",
    "edges = extract_edge_features(image)\n",
    "\n",
    "# Detect keypoints\n",
    "keypoints_sift, descriptors_sift = detect_keypoints_sift(image, max_keypoints=200)\n",
    "keypoints_orb, descriptors_orb = detect_keypoints_orb(image, max_keypoints=200)\n",
    "\n",
    "# Detect contours\n",
    "contours = detect_contours(image, min_area=500)\n",
    "\n",
    "print(f\"üìä Feature Extraction Results:\")\n",
    "print(f\"  ‚Ä¢ Canny edges: {edges['canny'].sum() // 255} pixels\")\n",
    "print(f\"  ‚Ä¢ SIFT keypoints: {len(keypoints_sift)}\")\n",
    "print(f\"  ‚Ä¢ ORB keypoints: {len(keypoints_orb)}\")\n",
    "print(f\"  ‚Ä¢ Contours: {len(contours)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307f18a3",
   "metadata": {},
   "source": [
    "## 3.3 Visualize Edge Detection Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652f482e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert for display\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "axes[0, 0].imshow(image_rgb)\n",
    "axes[0, 0].set_title('Original Image', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(edges['canny'], cmap='gray')\n",
    "axes[0, 1].set_title('Canny Edge Detection', fontsize=12)\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[1, 0].imshow(edges['sobel'], cmap='gray')\n",
    "axes[1, 0].set_title('Sobel Edge Detection', fontsize=12)\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(edges['laplacian'], cmap='gray')\n",
    "axes[1, 1].set_title('Laplacian Edge Detection', fontsize=12)\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "plt.suptitle('Edge Detection Methods', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80da9757",
   "metadata": {},
   "source": [
    "## 3.4 Run YOLO Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b42a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference\n",
    "results = model(image, conf=0.25, verbose=False)\n",
    "\n",
    "# Extract results\n",
    "result = results[0]\n",
    "boxes = result.boxes.xyxy.cpu().numpy()\n",
    "confidences = result.boxes.conf.cpu().numpy()\n",
    "class_ids = result.boxes.cls.cpu().numpy().astype(int)\n",
    "class_names = result.names\n",
    "\n",
    "print(f\"\\nüêæ Detected {len(boxes)} pet(s):\")\n",
    "for i, (box, class_id, conf) in enumerate(zip(boxes, class_ids, confidences)):\n",
    "    class_name = class_names[class_id]\n",
    "    print(f\"  {i+1}. {class_name.upper()} - confidence: {conf:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d261ee0b",
   "metadata": {},
   "source": [
    "## 3.5 Compare Standard vs Enhanced Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8442a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard YOLO detection\n",
    "standard_output = draw_detections(\n",
    "    image,\n",
    "    boxes.tolist(),\n",
    "    class_names,\n",
    "    confidences.tolist(),\n",
    "    class_ids.tolist()\n",
    ")\n",
    "\n",
    "# Enhanced detection with edges\n",
    "enhanced_edges = draw_enhanced_detections(\n",
    "    image,\n",
    "    boxes.tolist(),\n",
    "    class_names,\n",
    "    confidences.tolist(),\n",
    "    class_ids.tolist(),\n",
    "    show_edges=True,\n",
    "    show_keypoints=False\n",
    ")\n",
    "\n",
    "# Enhanced detection with keypoints\n",
    "enhanced_keypoints = draw_enhanced_detections(\n",
    "    image,\n",
    "    boxes.tolist(),\n",
    "    class_names,\n",
    "    confidences.tolist(),\n",
    "    class_ids.tolist(),\n",
    "    show_edges=False,\n",
    "    show_keypoints=True\n",
    ")\n",
    "\n",
    "# Enhanced detection with both\n",
    "enhanced_both = draw_enhanced_detections(\n",
    "    image,\n",
    "    boxes.tolist(),\n",
    "    class_names,\n",
    "    confidences.tolist(),\n",
    "    class_ids.tolist(),\n",
    "    show_edges=True,\n",
    "    show_keypoints=True\n",
    ")\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "axes[0, 0].imshow(cv2.cvtColor(standard_output, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 0].set_title('Standard YOLO Detection', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(cv2.cvtColor(enhanced_edges, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 1].set_title('YOLO + Edge Detection', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[1, 0].imshow(cv2.cvtColor(enhanced_keypoints, cv2.COLOR_BGR2RGB))\n",
    "axes[1, 0].set_title('YOLO + Keypoints', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(cv2.cvtColor(enhanced_both, cv2.COLOR_BGR2RGB))\n",
    "axes[1, 1].set_title('YOLO + Edges + Keypoints', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "plt.suptitle('Detection Method Comparison', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1faac399",
   "metadata": {},
   "source": [
    "## 3.6 Analyze Detection Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf22bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each detection, analyze the features within the bounding box\n",
    "for i, (box, class_id, conf) in enumerate(zip(boxes, class_ids, confidences)):\n",
    "    x1, y1, x2, y2 = map(int, box)\n",
    "    class_name = class_names[class_id]\n",
    "    \n",
    "    # Extract region\n",
    "    region = image[y1:y2, x1:x2]\n",
    "    \n",
    "    # Analyze features in region\n",
    "    region_edges = extract_edge_features(region)\n",
    "    region_keypoints_orb, _ = detect_keypoints_orb(region, max_keypoints=100)\n",
    "    \n",
    "    print(f\"\\n{i+1}. {class_name.upper()} Detection Analysis:\")\n",
    "    print(f\"   Bounding Box: [{x1}, {y1}] to [{x2}, {y2}]\")\n",
    "    print(f\"   Region size: {x2-x1} x {y2-y1} pixels\")\n",
    "    print(f\"   Edge pixels (Canny): {region_edges['canny'].sum() // 255}\")\n",
    "    print(f\"   ORB keypoints in region: {len(region_keypoints_orb)}\")\n",
    "    print(f\"   Confidence: {conf:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5c505e",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**What we accomplished:**\n",
    "- ‚úÖ Integrated YOLOv8 object detection with edge detection\n",
    "- ‚úÖ Combined multiple computer vision techniques\n",
    "- ‚úÖ Created enhanced visualization options\n",
    "- ‚úÖ Analyzed feature distributions in detected regions\n",
    "\n",
    "**Use cases:**\n",
    "- Enhanced visual analysis for debugging detection issues\n",
    "- Feature-rich representations for downstream tasks\n",
    "- Understanding what the model \"sees\" in detected regions\n",
    "\n",
    "**Next steps:**\n",
    "- Fine-tune YOLO on custom pet dataset\n",
    "- Add tracking for video streams\n",
    "- Deploy as a web service"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
