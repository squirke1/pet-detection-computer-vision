{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6805a7c0",
   "metadata": {},
   "source": [
    "# YOLOv8 Pet Detection - Initial Exploration\n",
    "\n",
    "This notebook provides a quick start guide for exploring YOLOv8 pet detection with basic inference examples.\n",
    "\n",
    "## Objectives\n",
    "1. Load a pre-trained YOLOv8 model\n",
    "2. Run inference on sample images\n",
    "3. Visualize detection results\n",
    "4. Test on different pet images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82850967",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3995ef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.cwd().parent / 'src'))\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"✅ Imports successful!\")\n",
    "print(f\"YOLO version: {YOLO.__version__ if hasattr(YOLO, '__version__') else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c91daa",
   "metadata": {},
   "source": [
    "## 2. Load Pre-trained Model\n",
    "\n",
    "We'll use a pre-trained YOLOv8n model that can detect 80 classes from the COCO dataset, including cats (class 15) and dogs (class 16)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa51e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model_path = Path.cwd().parent / 'models' / 'yolov8n-pets.pt'\n",
    "model = YOLO(str(model_path))\n",
    "\n",
    "print(f\"✅ Model loaded from: {model_path}\")\n",
    "print(f\"Model type: {type(model)}\")\n",
    "print(f\"\\nCOCO classes include: cat (15), dog (16), bird, horse, bear, etc.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8011ca3b",
   "metadata": {},
   "source": [
    "## 3. Test Detection on Sample Image\n",
    "\n",
    "Let's run inference on a sample image to verify the model works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd9bc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for sample images\n",
    "data_dir = Path.cwd().parent / 'data' / 'raw'\n",
    "sample_images = list(data_dir.glob('*.jpg')) + list(data_dir.glob('*.png'))\n",
    "\n",
    "if sample_images:\n",
    "    test_image = str(sample_images[0])\n",
    "    print(f\"Using test image: {Path(test_image).name}\")\n",
    "else:\n",
    "    print(\"⚠️  No sample images found in data/raw/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285c3add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference\n",
    "if sample_images:\n",
    "    results = model(test_image, conf=0.3)\n",
    "    \n",
    "    print(f\"\\n✅ Inference complete!\")\n",
    "    print(f\"Detections: {len(results[0].boxes)} objects found\")\n",
    "    \n",
    "    # Show what was detected\n",
    "    for box in results[0].boxes:\n",
    "        cls_id = int(box.cls[0])\n",
    "        conf = float(box.conf[0])\n",
    "        class_name = model.names[cls_id]\n",
    "        print(f\"  - {class_name} (confidence: {conf:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f554e7bd",
   "metadata": {},
   "source": [
    "## 4. Visualize Results\n",
    "\n",
    "Display the original image with bounding boxes drawn on detected objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512b22ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sample_images:\n",
    "    # Get annotated image\n",
    "    annotated_img = results[0].plot()\n",
    "    \n",
    "    # Convert BGR to RGB for matplotlib\n",
    "    annotated_img_rgb = cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Display\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(annotated_img_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.title('YOLOv8 Pet Detection Results', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75dc439",
   "metadata": {},
   "source": [
    "## 5. Next Steps\n",
    "\n",
    "This notebook demonstrates basic YOLOv8 inference. For more advanced features:\n",
    "- **Notebook 02**: Edge detection and keypoint features\n",
    "- **Notebook 03**: Combined YOLO + edge detection pipeline\n",
    "- **API**: REST API at `http://localhost:8000` for web-based inference\n",
    "- **Scripts**: Batch processing with `src/infer_on_folder.py`"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
